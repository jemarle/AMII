---
title: "Proyecto: Reglas de Asociación (Aprendizaje Máquina II)"
author: "Carlos Sánchez Polo y Jesús Martínez Leal"
date: "`r Sys.Date()`"
output:
  html_document:
    echo: yes
    number_sections: no
    theme: readable
    toc: yes
  html_notebook:
    toc: yes
subtitle: Máster Ciencia de Datos UV
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# Configuración general de chunks
library(knitr)
options(width = 100)
knitr::opts_chunk$set(echo = F, message = T, error = F, warning = F, comment = NA, dpi = 100, tidy = T, cache.path = '.cache/', fig.path = './figure/', include = F, fig.pos = "H", fig.align = "center")
```

Como es habitual, cargamos las librerías que necesitamos al inicio del documento.

```{r librerias, message = T, include = F, echo = F}
# Carga de librerías necesarias con pacman
if (!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}
pacman::p_load(float, readr, stringr, tidyr, dplyr, readxl, ggplot2, forcats, kableExtra, greekLetters, fitdistrplus, OneR, caret, OneR, arules, arulesCBA, arulesViz, Rgraphviz, DescTools, vcd)
```
```{r spetial_func_capFig, echo = F}
#Determine the output format of the document
outputFormat   = opts_knit$get("rmarkdown.pandoc.to")

#Figure and Table Caption Numbering, for HTML do it manually
capTabNo = 1; capFigNo = 1;

#Function to add the Table Number
capTab = function(x){
  if(outputFormat == 'html'){
    x = paste0("Table ",capTabNo,". ",x)
    capTabNo <<- capTabNo + 1
  }; x
}

#Function to add the Figure Number
capFig = function(x, y){
  if(outputFormat == 'html'){
    x = paste0("Figure ",capFigNo,". ",x, "\\label{fig:", y, "}")
    capFigNo <<- capFigNo + 1
  }; x
}
```

## Qualitative Bankruptcy Data Set

Utilizaremos una versión parecida del conjunto de datos `Qualitative_Bankruptcy Data Set` del repositorio *UCI Machine Learning* para trabajar el estudio de las variables Categóricas/Cualitativas y la bondad de las reglas de Asociación para extraer conocimiento de un conjunto de datos, en este caso, predecir la bancarrota (*Bankruptcy*) en base a parámetros cuantitativos/cualitativos preparados por expertos.

Cargamos el fichero `Qualitative_Bankruptcy.num.txt` y creamos el `data.frame` `QB`.

```{r lectura_QB}
QB <- read.table("./data/Qualitative_Bankruptcy.num.txt", header = FALSE, sep = ",", stringsAsFactors = TRUE)
```

Asignamos nombres válidos a las columnas del `data.frame` (`make.names` se usa para asegurarnos que no contiene símbolos raros). Hay más información en el fichero `Qualitative_Bankruptcy.info.txt`

```{r colnames_QB}
colnames(QB) <- make.names(c("Industrial Risk", "Management Risk", 
                               "Financial Flexibility","Credibility",
                               "Competitiveness", "Operating Risk", 
                               "Bankruptcy"))
```

La información sobre este conjunto de datos se muestra a continuación:

```{r visualizacion_QB, include = T}
str(QB)
head(QB)
```
En primer lugar, para poner un poco de contexto de lo que estamos haciendo, se explica un poco las variables que aparecen en el conjunto de datos.

- `Industrial Risk` (Riesgo industrial). Se refiere al riesgo asociado con el sector en el que opera la empresa. Ciertos sectores pueden ser más volátiles o estar más expuestos a factores macroeconómicos que otros.

- `Management Risk` (Riesgo de gestión). Este indicador evalúa la calidad de la gestión de la empresa. Se centra en la capacidad de los directivos para tomar decisiones efectivas, implementar estrategias exitosas y gestionar eficazmente los recursos.

- `Financial Flexibility` (Flexibilidad financiera). Se refiere a la capacidad de la empresa para manejar cambios en su estructura financiera y cumplir con sus obligaciones financieras, especialmente en situaciones adversas como una disminución de ingresos o aumento de costos.

- `Credibility` (Credibilidad). Evalúa la reputación de empresa en el mercado. Una buena reputación puede influir en la capacidad de la empresa para atraer inversionistas, clientes y socios, mientras que una mala reputación puede tener el efecto opuesto.

- `Competitiveness` (Competitividad). Se refiere a la capacidad de la empresa para competir con éxito en su mercado objetivo. Puede incluir factores como la calidad de productos o servicios, eficiencia operativa, innovación, capacidad de adaptación a condición de mercado, etc.

- `Operating Risk` (Riesgo operativo). Este evalúa el riesgo asociado con las operaciones comerciales diarias de la empresa. Esto puede incluir riesgos relacionados con la cadena de suministro, la calidad del producto, seguridad laboral, entre otros.

Estas variables, en resumen, nos proporcionan una visión holística de la salud financiera y operativa de una empresa, lo que permite a los analistas y inversores evaluar su riesgo de bancarrota (relacionado con `Bankruptcy`).

Las variables numéricas representan un valor entre 0 y 10 e indican la valoración del experto para cada variable. Discretizaremos estas en 3 factores ordenados **QB** de **manera no supervisada**, con el objetivo de estimar la clase `Bankruptcy`. \

La etiqueta asociada a valores bajos será `N` (negative), la etiqueta de valores altos será `P` (positive) y el resto corresponderá a la etiqueta `A` (average). \

Se utiliza la función `discretize()` del paquete `arules` con cada método que este nos ofrece (`interval`, `frequency` y `cluster`).

```{r bin_columns}
columna_clase <- "Bankruptcy"
columns_to_discretize <- setdiff(names(QB), columna_clase)

methods <- c("interval", "frequency", "cluster")

discretization_configs <- list(
  interval = list(
    method = "interval",
    breaks = 3,
    labels = c("N", "A", "P")
  ),
  frequency = list(
    method = "frequency",
    breaks = 3,
    labels = c("N", "A", "P")
  ),
  cluster = list(
    method = "cluster",
    breaks = 3,
    labels = c("N", "A", "P")
  )
)

discretizedQB_list <- list()


for (method in methods) {

  names_list <- setNames(rep(list(discretization_configs[[method]]), length(columns_to_discretize)), columns_to_discretize)
  
  discretizedQB <- discretizeDF(QB[, columns_to_discretize], methods = names_list)
  discretizedQB[[columna_clase]] <- QB[[columna_clase]]
  
  discretizedQB_list[[method]] <- discretizedQB
}

head(discretizedQB_list$interval)
head(discretizedQB_list$frequency)
head(discretizedQB_list$cluster)
```

Nos aseguramos que todas las variables son factores de 3 niveles ordenados que además respetan `N` < `A` < `P`. Además, la primera clase de `Bankruptcy` será la de etiqueta `B` (bancarrota).

```{r conversion_factores_ordenados, include = T}
for (method in methods) {
  names_list <- setNames(rep(list(discretization_configs[[method]]), length(columns_to_discretize)), columns_to_discretize)
  
  discretizedQB <- discretizeDF(QB[, columns_to_discretize], methods = names_list)
  discretizedQB[[columna_clase]] <- QB[[columna_clase]]
  
  for (i in 1:(ncol(discretizedQB) - 1)) {
    discretizedQB[[i]] <- factor(discretizedQB[[i]], levels = c("N", "A", "P"), ordered = TRUE)
  }
  
  if (levels(discretizedQB[[columna_clase]])[1] == "B") {
    print(paste("Para el método", method, "el primer nivel de la clase Bankruptcy es:", levels(discretizedQB[[columna_clase]])[1]))
  } else {
    print(paste("Para el método", method, "el primer nivel de la clase Bankruptcy no es 'B'."))
  }
  
  discretizedQB_list[[method]] <- discretizedQB
}
str(discretizedQB_list)
```

## Análisis Cualitativo

Realizaremos a continuación un breve estudio del conjunto discretizado para determinar si es apropiado resolver el problema de clasificación correcta de la variable `Bankruptcy`.

### Análisis univariante de las variables Cualitativas

A continuación, se calculan las tablas de frecuencia correspondientes a cada una de las clases discretizadas anteriormente. Estas se mostrarán de una manera visual con gráficos de barras, haciéndose una diferencia entre los distintos tipos de `method` en el `discretize()`.


```{r tabla_frecuencias}
obtener_tabla_frecuencias <- function(columna) {
  tabla_frecuencias <- table(columna)
  df_frecuencias <- as.data.frame(tabla_frecuencias)
  colnames(df_frecuencias) <- c("Categoria", "Frecuencia")
  df_frecuencias$Porcentaje <- prop.table(tabla_frecuencias) * 100
  return(df_frecuencias)
}

tablas_frecuencias <- list()

for (method_name in names(discretizedQB_list)) {

  discretized_data <- discretizedQB_list[[method_name]]
  tablas_frecuencias[[method_name]] <- lapply(discretized_data, obtener_tabla_frecuencias)
}
str(tablas_frecuencias)
```

```{r grafico_frecuencias_porcentajes, include = T, fig.cap = capFig("Frecuencias para las distintas variables con los distintos métodos", y = "grafico_frecuencias_porcentajes")}
plots_frecuencia <- list()
plots_porcentaje <- list()


for (method in names(tablas_frecuencias)) {

  tabla_total <- bind_rows(tablas_frecuencias[[method]], .id = "Variable") # poner en largo el dataframe

  tabla_total <- unnest(tabla_total, cols = Frecuencia)
  
  # Gráfico de frecuencias
  plot_frecuencia <- ggplot(tabla_total, aes(x = Categoria, y = Frecuencia, fill = Categoria)) +
    geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
    facet_wrap(~ Variable, scales = "free") +
    labs(title = paste("Frecuencias de variables cualitativas -", method), x = "Categoría", y = "Frecuencia") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  plots_frecuencia[[method]] <- plot_frecuencia
  
  # Gráfico de porcentajes
  #plot_porcentaje <- ggplot(tabla_total, aes(x = Categoria, y = Porcentaje, fill = Categoria)) +
  #  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  #  facet_wrap(~ Variable, scales = "free") +
  #  labs(title = paste("Porcentaje de variables cualitativas -", method), x = "Categoría", y = "Porcentaje") + 
  #  theme_minimal() +
  #  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  

  #plots_porcentaje[[method]] <- plot_porcentaje
}

plots_frecuencia
#plots_porcentaje
```

Observamos cómo las frecuencias dependen en medida de cómo se ejecuta la discretización de las variables numéricas a categóricas con la función `discretize()` y sus diferentes `method`. Aparece una mayor diferencia en el método `frequency`, en el que las variables anteriormente numéricas (todas menos `Bankruptcy`) pasan a tener todas las categorías con igualdad de frecuencia para cada una de las clases.

Por otra parte, los métodos `interval` y `cluster` son muy similares en este caso.


```{r plot_diferencia_discretize, include = T, fig.cap = capFig("Diferencias a la hora de discretizar entre los distintos métodos", y = "plot_diferencia_discretize")}

par(mfrow = c(2, 3), mar = c(4, 4, 2, 2))  


for (i in 1:length(columns_to_discretize)) {
  variable <- columns_to_discretize[i]
  hist(QB[[variable]], breaks = 40, main = "", xlab = variable, ylab = "Frecuencia", col = "lightgray")
  for (j in 1:length(discretizedQB_list)) { 
    method <- names(discretizedQB_list)[j]
    variable_discrete <- discretizedQB_list[[method]][[variable]]
    num_levels <- length(levels(variable_discrete))
    cut_points <- discretize(QB[[variable]], method = method, breaks = num_levels, onlycuts = TRUE)
    abline(v = cut_points, col = j + 1)  
  }
}


legend("topright", legend = names(discretizedQB_list), fill = 2:(length(discretizedQB_list) + 1))
```

En estos gráficos puede apreciarse lo que se comentó anteriormente de las diferencias entre los distintos métodos para discretizar. \

Observamos que la discretización por `cluster` y `interval` ha cogido como valor `N` (Negative) aproximadamente entre 0 y 3. La categoría `A` (Average) queda entre 3 y 7, mientras que la de `P` (Positive) de 7 a 10. \

Hemos visto también que en estas dos formas de discretización se asignan más valores de `N` que de las otras categorías para todas las variables del conjunto de datos. Esto nos puede llevar a pensar que ha habido cierta tendencia a valorar de manera algo estricta las cosas.


### Análisis bivariante de las variables Cualitativas

Pasamos a obtener la relación entre las variables (matrices de contingencia). Determinaremos el grado de asociación utilizando la **V de Cramer** (`CramerV`). \

Utilizaremos la función `PairApply` de la libería `DescTools` para calcular estadísticos para todos los pares. La función `PlotCorr` 


*Nota: La función PairApply de la librería DescTools permite calcular estadísticos para todos los pares. La función PlotCorr permite representar los resultados de PairApply.*

Representamos la matriz de valores de coeficientes de Cramer, medida que nos informa sobre la asociación entre variables categóricas. Es una versión normalizada del estadístico de chi-cuadrado, oscilando su valor entre 0 y 1.

```{r CramersMatrices, include = T}
cramerV_matrix <- list()

for (method in methods) {
  cramerV_matrix[[method]] <- PairApply(discretizedQB_list[[method]], FUN = CramerV)
}

cramerV_matrix
```
```{r plotCorrMatrix, include = T}
for (method in methods){
  PlotCorr(cramerV_matrix[[method]], main = "")
  title(main = paste("PlotCorr para el método", method), line = -20)
}
```

La última columna corresponde a los valores que tienen las distintas variables predictoras con la variable `Bankruptcy`. Un valor de CramerV superior a 0.7 está catalogado como una fuerte relación entre variables categóricas, implicando que `Financial.Flexibility`, `Credibility` y, sobre todo `Competitiveness`, muestran una clara dependencia sobre el valor obtenido para `Bankruptcy`.

Se muestran a continuación las matrices de contingencia entre las diferentes variables respecto a `Bankruptcy`.

```{r matrices_contingencia, include = T}
contingency_matrices <- list()

for (method in methods){
  for (variable in columns_to_discretize) {
    formula <- as.formula(paste(" ~ Bankruptcy + ", variable))
    contingency_matrices[[method]][[variable]] <- xtabs(formula, data = discretizedQB_list[[method]])
}

names(contingency_matrices[[method]]) <- NULL
}

contingency_matrices
```

Observamos que en los casos mencionados anteriormente concuerdan con lo que se dijo de una alta relación. Es fácil ver que una `Financial.Flexibility` negativa (`N`) suele llevar a tener bancarrota (`Bankruptcy` en `B`). Por el contrario, una positiva tiene fuerte relación a lo contrario. De manera similar pasa con `Credibility` y `Competitiveness`. 


Contrastaremos los resultados con los gráficos de Mosaico de los casos más relevantes. Por cuestiones de no saturar con demasiados plots, se muestra lo que ocurre con el método de `cluster` (similar a lo que ocurre con `interval`).

```{r mosaic_plots, include = T}
interest_var <- c("Financial.Flexibility", "Credibility", "Competitiveness")
methods_plot <- c("cluster")

for (method in methods_plot){
  for (variable in interest_var){
    formula <- as.formula(paste("~", "Bankruptcy", "+", variable))
    mosaic(formula = formula, data = discretizedQB_list[[method]], shade = TRUE, main = paste("Método de", method))
    assoc(formula = formula, data = discretizedQB_list[[method]], shade = TRUE, main = paste("Método de", method))
  }
}
```
Puede verse claramente lo que se comentaba anteriormente. En estas 3 variables hay cierta predisposición a que no haya bancarrota si se tiene un resultado `Average` o `Positive` (sobre todo). Justamente con `Negative` hay predisposición a lo contrario, entrar en bancarrota.


## Reglas de Asociación

Transforma el `data.frame` en *transactions* con el nombre `QBt` y analízalas con `summary`.

```{r transactions_create, include = T}
QBt <- list()

for (method in methods){
  QBt[[method]] <- transactions(discretizedQB_list[[method]])
}

summary(QBt$cluster)

itemInfo(QBt$cluster)
itemLabels(QBt$cluster)
```
Como puede verse, tenemos un total de 250 filas / itemsets, así como 20 columnas / items que representan todas las posibilidades de variables con sus posibles niveles. 

Los 5 items más frecuentes (con nivel correspondiente) se muestran a continuación.

```{r frequencyPlot, include = T}
itemFrequencyPlot(QBt$cluster, topN = 5)
```
Una tabla de contingencia entre todos los pares de variables (combinación de pares de *items*) se muestra a continuación:

```{r crosstable, include = T}
crossTable(QBt$cluster)
```

```{r crossTable_top_vars}
table_trans <- crossTable(QBt$cluster, sort = TRUE)
table_trans[1:5, 1:5]
```
Vemos aquí que el número más elevado se obtiene entre la combinación de `Bankruptcy = B` y `Financial.Flexibility = N`.


`Obtén las reglas de asociación que tienen, al menos, un `support` del 10% y una `confidence` del 100%. ¿Cuántas reglas se obtienen?`

Utilizamos la función `apriori()` del paquete `arules` para este cometido.

```{r custom_rule_supp_conf}
support <- 0.1
confidence <- 1

rules <- apriori(data = QBt$cluster, parameter = list(support = support, confidence = confidence, target = "rules"))
summary(rules)
```
Se han obtenido un total de 88 reglas, tal y como se muestra arriba.

```{r rules_items}
inspect(items(rules))
```
Las reglas pueden representarse en un grafo interactivo:

```{r grafo_rules, include = T}
plot(rules, method = "graph", engine = "htmlwidget")
```

Resulta obvio de ver que en el grafo tenemos 2 zonas bien diferenciadas: por una la que se relaciona con `Bankruptcy = B` y por otra la que se relaciona con `Bankruptcy = NB`.

`Muestra las 3 primeras reglas ordenadas por `lift`.`

```{r sort_rules_lift}
inspect(head(arules::sort(rules, by = "lift"), n = 3))
```

`Obtén las reglas de asociación que tengan como **ANTECEDENTE** `Bankruptcy=B` . Reduce el número de reglas con las condiciones `lift>2 & count>50`. ¿Observas algún patrón/curiosidad en estas reglas?`

*Nota: Representar las reglas ayuda en la interpretación.*

Las reglas con ese tipo de condiciones se muestran a continuación:

```{r rules_lhs_bankruptcy, include = T}
inspect(subset(rules, subset = lhs %pin% c("Bankruptcy=B") & lift > 2 & count > 50 ))
```

Podemos representar estas reglas haciendo uso de `plot()`.

```{r rules_filter_plot, include = T}
rules_filtered <- subset(rules, subset = lhs %pin% c("Bankruptcy=B") & lift > 2 & count > 50 )
rules_sort <- arules::sort(rules_filtered, by = "support")

plot(rules_sort, measure = c("support", "lift"), shading = "count", engine = "htmlwidget")
```


```{r rules_sort_plot, include = T}
plot(rules_sort, method = "graph", engine = "htmlwidget" )
```


`Obtén las reglas de asociación en las que **no** aparezca la variable`Bankruptcy` (ni en el antecedente ni en la consecuencia). Representa las reglas. ¿Para qué sirven estas reglas/grafo si no aparece la variable objetivo?`

Se utiliza un `subset()` con lo obtenido anteriormente para que no aparezca dicha variable.

```{r noBankrupcty_rules, include = T}
itemLabels_filter <- setdiff(itemLabels(rules), c("Bankruptcy=B", "Bankruptcy=NB")) # hallar conjunto diferencia

rules_no_bank <- subset(rules, subset = (lhs %oin% itemLabels_filter) & (rhs %oin% itemLabels_filter)) # básicamente exigimos que esté en ese subconjunto de lhs y rhs
summary(rules_no_bank)

inspect(rules_no_bank)
```

Pasa a graficarse a continuación en modo de grafo lo obtenido:

```{r graph_rules_no_bank, include = T}
plot(rules_no_bank, method = "graph", engine = "htmlwidget")
```

Las reglas de asociación, incluso cuando no incluyen la variable objetivo, pueden ser valiosas para comprender relaciones entre otras variables en el conjunto de datos.
Destaca aquí por ejemplo la regla de `{Financial.Flexibility=N, Credibility=N, Operating.Risk=N} = > 	{Competitiveness=N}`.

La regla sugiere que cuando una empresa afronta dificultades financieras, falta de credibilidad y alto riesgo operativo, es probable que la competitividad se vea afectada negativamente.



## Predicción con reglas de asociación

Desarrolla un modelo de clasificación basado en reglas de asociación para estimar la Bancarrota. Comprueba la bondad del modelo (sensibilidad y especificidad) dividiendo el conjunto de datos en Entrenamiento 80% y Test 20%. Utiliza la función `createDataPartition` y `confusionMatrix` del paquete `caret`.

```{r fixed_seed}
set.seed(666)
```

Dividimos nuestro conjunto de datos en train y test con una proporción de 80% - 20%, respectivamente.

```{r train_and_test}
trainIndex <- createDataPartition(discretizedQB_list$cluster$Bankruptcy, p = 0.8, times = 1, list = FALSE)


trainData <- discretizedQB_list$cluster[trainIndex, ]
testData <- discretizedQB_list$cluster[-trainIndex, ]
```

Puede comprobarse que la proporción de clases en train y test es prácticamente la misma:

```{r prop_train_test}
pTrain <- sum(trainData$Bankruptcy == "B") / sum(trainData$Bankruptcy == "NB")
pTest <- sum(testData$Bankruptcy == "B") / sum(testData$Bankruptcy == "NB")

pTrain
pTest
```

### OneR

Veamos primero lo que nos ofrece el modelo de `OneR. `OneR` es un algoritmo de clasificación simple, pero preciso, que genera una regla para cada predictor en los datos, y luego selecciona la regla con el error total más pequeño como su "regla única".

```{r oner_model}
modelOneR <- OneR(formula =  Bankruptcy ~ ., data = trainData)
```

```{r summary_oneR, include = T}
summary(modelOneR)
```
Vemos que se obtiene una `accuracy` del 98% con un modelo tan sencillo de regla única, lo cual es bastante sorprendente. El p-valor tan bajo indica que hay una asociación significativa entre las variables de `Competitiveness` y `Bankruptcy`.

Evaluaremos primero este modelo sobre los propios datos de Training:

```{r oneR_train_evaluate, include = T}
predict_bank_train <- predict(modelOneR, trainData)
matrix_oneR_train <- confusionMatrix(predict_bank_train, trainData$Bankruptcy)

matrix_oneR_train
```
La sensibilidad (`Sensivity`) representa la proporción de positivos reales que se clasificaron correctamente como positivos, mientras que la especificidad (`Specifity`) representa la proporción de negativos reales que se clasificaron correctamente como negativos.

```{r oneR_test_evaluate, include = T}
predict_bank_test <- predict(modelOneR, testData)
matrix_oneR_test <- confusionMatrix(predict_bank_test, testData$Bankruptcy)

matrix_oneR_test
```
En el conjunto de testing se obtuvo un `accuracy` de 1 para esta partición de los datos, si bien es cierto que el intervalo de confianza del 95% de esta va hasta 0.9275 en la cota inferior.

### CBA

Las siglas de `CBA` responden a *Classification Based on Associations*.

En CBA, se extraen reglas de asociación a partir de los datos y luego se utilizan estas reglas para clasificar nuevas instancias. Estas reglas de asociación pueden proporcionar información sobre cómo las variables predictoras están relacionadas entre sí y con la variable objetivo.

En el proceso general se tiene:

- Extracción de reglas de asociación: con algoritmos como APRIORI.
- Generación de reglas de clasificación.
- Clasificación de nuevas instancias.


Pasemos a aplicar el modelo con un `support = 0.2` y `confidence = 1`.

```{r modelCBA}
modelCBA <- CBA(Bankruptcy ~ ., data = trainData, support = 0.2, confidence = 1, balanceSupport = TRUE, pruning = "M1")
summary(modelCBA)
```
Pasamos a inspeccionar las reglas de este:

```{r rules_inspect, include = T}
inspect(arules::sort(modelCBA$rules, by = "lift"))
```

```{r vis_reglas_cba, include = T}
plot(modelCBA$rules, measure = c("support", "lift"), shading = "confidence", engine = "htmlwidget")
plot(modelCBA$rules, method = "graph", engine = "htmlwidget")
```

Evaluamos el modelo CBA sobre los conjuntos de entrenamiento y test:

```{r evaluate_train_cba, include = T}
predict_bank_train_CBA <- predict(modelCBA, trainData)
matrix_cba_train <- confusionMatrix(predict_bank_train_CBA, trainData$Bankruptcy)
matrix_cba_train
```

Obtenemos en el propio conjunto de training un `accuracy` de 1, lo que resulta algo mejor que en el modelo de regla única del OneR.

```{r evaluate_test_cba, include = T}
predict_bank_test_CBA <- predict(modelCBA, testData)
matrix_cba_test <- confusionMatrix(predict_bank_test_CBA, testData$Bankruptcy)
matrix_cba_test
```

En el conjunto de test también se obtiene un `accuracy` de 1.

```{r}
plot(modelCBA$rules, method = "graph", engine = "graphviz")
```
[Reflexiones sobre el modelo basado en reglas:]{.underline}

**\>\>\>\<\<\<Conclusiones del modelo basado en reglas...\>\>\>\<\<\<**

¿has utilizado todas las variables en el modelo y por qué?

¿has seleccionado reglas y por qué? ¿en base a qué criterio?
